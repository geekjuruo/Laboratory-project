### ABSTRACT

使用动态端口号，伪装技术和加密来避免检测的许多对等（P2P）应用程序使用基于端口或基于有效负载的分析对网络流量进行分类变得越来越困难。另一种方法是通过在网络上进行通信时利用应用程序的独特特征来对流量进行分类。我们采用后一种方法，并演示了如何使用聚类分析有效地识别仅使用传输层统计信息的类似流量组。我们的工作考虑了两个以前未用于网络流量分类的无监督聚类算法，即K-Means和DBSCAN。我们使用经验的Internet跟踪评估这两种算法，并将它们与之前使用的AutoClass算法进行比较。实验结果表明，K-Means和DBSCAN都能很好地工作，并且比AutoClass快得多。我们的结果表明，虽然DBSCAN与K-Means和AutoClass相比具有较低的准确度，但DBSCAN产生更好的聚类。

### INTRODUCTION

根据应用类型准确识别和分类网络流量是许多网络管理任务的重要组成部分，例如流优先级划分，流量整形/监管和诊断监控。例如，网络运营商可能想要识别和限制（或阻止）来自对等（P2P）文件共享应用的流量，以管理其带宽预算并确保业务关键应用的良好性能。与网络管理任务类似，许多网络工程问题（例如工作负载表征和建模，容量规划和路由配置）也可以从准确识别网络流量中受益。在本文中，我们根据我们使用称为聚类的机器学习方法来解决网络流量识别问题的经验提供了初步结果。在本节的其余部分，我们将讨论为什么聚类有用，讨论本文的具体贡献，并概述我们正在进行的工作。

传统的流量分类方法依赖于将应用程序映射到众所周知的端口号，并且在过去非常成功。 为了避免通过这种方法进行检测，P2P应用程序开始使用动态端口号，并开始通过使用常用协议（如HTTP和FTP）的端口号进行自我识别。 最近的许多研究证实，基于端口的网络流量识别是无效的[8,15]。

为了解决基于端口的分类的上述缺点，已经提出了几种基于有效载荷的分析技术[3,6,9,11,15]。 在这种方法中，分析数据包有效负载以确定它们是否包含已知应用程序的特征签名。 研究表明，这些方法对包括P2P流量在内的当前互联网流量非常有效。 实际上，一些商业分组整形工具已经开始使用这些技术。 然而，像BitTorrent这样的P2P应用程序开始通过使用混淆方法（例如纯文本密码，可变长度填充和/或加密）来逃避这种技术。 此外，还有一些其他缺点。 首先，这些技术仅识别签名可用的流量，并且无法对任何其他流量进行分类。 其次，这些技术通常需要增加处理和存储容量。

基于端口和基于有效负载的分析的局限性推动了传输层统计用于流量分类[8,10,12,14,17]。 这些分类技术依赖于以下事实：当在网络上通信时，不同的应用程序通常具有不同的行为模式。 例如，使用FTP的大文件传输将具有比即时消息传递客户端向其他客户端发送短暂的偶然消息更长的连接持续时间和更大的平均数据包大小。 类似地，一些P2P应用程序（如BitTorrent 1）可以与FTP数据传输区分开来，因为这些P2P连接通常是持久的并且双向发送数据; FTP数据传输连接是非持久性的，只能单向发送数据。 传输层统计信息（例如发送的数据包总数，每个方向发送的字节数，连接持续时间以及数据包的平均大小）表征这些行为。

在本文中，我们探讨了使用称为聚类的机器学习方法来仅使用传输层统计对流量进行分类。 聚类分析是在一组对象中识别类的最重要方法之一，并已被用作生物学，金融学和计算机科学等许多领域的工具。 McGregor等人最近的工作。 [10]和Zander等人。 [17]表明，聚类分析能够仅使用传输层特征对网络流量进行分组。 在本文中，我们通过评估两个聚类算法，即K-Means [7]和DBSCAN [5]来证实他们的观察结果，据我们所知，这些算法以前没有应用于这个问题。 此外，作为基线，我们提出了之前考虑的AutoClass [1]算法[10,17]的结果。

本文评估的算法使用无监督学习机制，其中未标记的训练数据基于相似性进行分组。 这种对未标记的训练数据进行分组的能力是有利的，并且提供了一些实际的好处，而不是学习需要标记训练数据的方法（在第2节中讨论）。 尽管所选算法使用无监督学习机制，但是这些算法中的每一个都基于不同的聚类原则。 K-Means聚类算法是一种基于分区的算法[7]，DBSCAN算法是一种基于密度的算法[5]，而AutoClass算法是一种基于概率模型的算法[1]。 特别是为什么选择K-Means和DBSCAN算法的一个原因是它们在聚类数据方面比以前使用的AutoClass算法快得多。

我们使用两个经验跟踪来评估算法：来自奥克兰大学的众所周知的公共互联网流量跟踪，以及我们从卡尔加里大学的互联网连接中收集的最新信息。基于它们生成具有单个应用的高预测能力的集群的能力来比较算法。我们展示了群集适用于各种不同的应用程序，包括Web，P2P文件共享和文件传输，AutoClass和K-Means算法的精度在我们的结果中超过85％，而DBSCAN的精度达到75％。此外，我们分析了不同算法产生的每个聚类中的聚类数和对象数。通常，算法将对象分组到几个“好”聚类中的能力对于减少标记聚类所需的处理量特别有用。我们表明，虽然DBSCAN的整体准确度较低，但它形成的聚类最准确。此外，我们发现通过仅查看DBSCAN的一些群集，可以识别出很大一部分连接。

我们的工作正在进行中。初步结果表明，聚类确实是一种有用的交通识别技术。我们的目标是使用聚类技术作为构建块来构建高效且准确的分类工具。这种聚类工具将包括两个阶段：模型构建阶段和分类阶段。在第一阶段，无监督聚类算法聚类训练数据。这会产生一组聚类，然后将其标记为我们的分类模型。在第二阶段，该模型用于开发能够标记在线和离线网络流量的分类器。我们注意到，与在线分类相比，离线分类相对容易，因为在前一种情况下可以很容易地获得聚类算法所需的流量统计;后者需要使用估算技术进行流量统计。我们还应该注意到，这种方法不是流量分类问题的“灵丹妙药”。虽然模型构建阶段确实自动生成集群，但我们仍需要使用其他技术来标记集群（例如，有效负载分析，手动分类，基于端口的分析或其组合）。此任务是可管理的，因为该模型通常使用小型数据集构建。

我们认为，为了建立一个准确的分类器，必须使用一个好的分类模型。 在本文中，我们专注于模型构建步骤。 具体来说，我们研究哪种聚类算法生成最佳模型。 我们目前正在研究为K-Means和DBSCAN构建有效的分类器并测试算法的分类准确性。 我们还研究了模型应该重新训练的频率（例如，每天，每周或每月）。

本文的其余部分安排如下。 第2节回顾了不同的互联网流量分类方法，包括使用聚类分析的方法。第3节概述了本文研究的聚类算法所采用的理论和方法。 第4节和第5节分别介绍了我们的方法，并分别列出了我们的实验结果。 第6节讨论了实验结果。 第7节介绍了我们的结论。

### BACKGROUND

有几种技术使用传输层信息来解决与基于有效载荷的分析相关的问题以及基于端口的识别的有效性降低。 麦格雷戈等人。 利用传输层属性[10]，利用聚类分析对流进行分组的能力。 然而，作者没有评估分类的准确性以及哪些流属性产生最佳结果。 Zander等人。 通过使用另一个称为Au-toClass [1]的期望最大化（EM）算法[2]来扩展这项工作，并分析要使用的最佳属性集[17]。 [10]和[17]都只测试EM算法实现的贝叶斯聚类技术。 EM算法的学习时间较慢。 本文评估了与以前工作中使用的EM算法不同且更快的聚类算法。

一些非聚类技术也使用传输层统计来对流量进行分类[8,9,12,14]。 Roughan等人。 使用最近邻和线性判别分析[14]。 连接持续时间和平均数据包大小用于将流量分为四个不同的类。 这种方法有一些局限性，因为这两个统计数据的分析可能不足以对所有应用程序类进行分类。

Karagiannis等。 提出一种技术，当P2P应用程序传输数据或建立连接时，使用P2P应用程序的独特行为来识别此流量[8]。 他们的结果表明，这种方法在准确性方面与基于有效载荷的识别方法相当。 最近，Karagiannis等人。 开发了另一种使用社交，功能和应用行为来识别所有类型流量的方法[9]。 这些方法侧重于更高级别的行为，例如与IP地址的并发连接数，并且不使用我们在本文中使用的单个连接的传输层特性。

在[12]中，Moore等人。使用监督机器学习算法NaNäveBayes作为分类器。摩尔等人。表明NäıveBayes方法具有高精度的流量分类。过度学习需要在建立模型之前标记训练数据。我们认为无监督聚类方法比监督学习方法具有一些优势。其中一个主要好处是可以通过检查分组以形成新集群的连接来识别新应用程序。受监督的方法无法发现新的应用程序，只能对其标记为训练数据的流量进行分类。标记连接时会出现另一个优点。由于我们集群的高精度，只需要识别一些连接，以便高度自信地标记集群。还要考虑集群数据集包含加密的P2P连接或其他类型的加密流量的情况。不会使用基于有效负载的分类来标记这些连接。因此，这些连接将被排除在监督学习方法之外，该监督学习方法只能使用标记的训练数据作为输入。这可能会降低监督方法的准确性。但是，无监督聚类方法没有这种限制。它可能会将加密的P2P流量放入具有其他未加密的P2P流量的群集中。通过查看群集中的连接，分析师可能能够看到未加密的P2P流量与加密流量之间的相似性，并得出结论可能是P2P流量。

### CLUSTERING ALGORITHMS

本节回顾了本工作中考虑的聚类算法，即K-Means，DBSCAN和AutoClass。 K-Means算法产生球形的簇，而DBSCAN算法具有产生非球形簇的能力。 DBSCAN能够找到的不同簇形状可以允许找到更好的簇集合，以最小化所需的分析量。 AutoClass算法使用贝叶斯方法，可以自动确定簇的数量。另外，它执行软聚类，其中对象被分数地分配给多个聚类。
Cluster 3.0 [4]软件套件用于获取K-Means聚类的结果。 DBSCAN结果来自WEKA软件套件[16]。使用[1]提供的实现获得AutoClass结果。
为了实现连接的聚类，必须首先建立相似（或距离）测量。虽然存在各种相似性测量，但欧几里德距离是聚类问题最常用的度量之一[7,16]。对于欧几里德距离，两个物体之间的小距离意味着强相似性，而大距离意味着低相似性。在特征的n维空间中，可以在对象x和y之间计算欧几里德距离，如下所示：

$$\operatorname{dist}(x, y)=\sqrt{\sum_{i=1}^{n}\left(x_{i}-y_{i}\right)^{2}}$$

n是每个对象中的要素数。 本文中的算法都使用欧几里德距离作为它们的相似性测量。 在这种情况下，对象将是连接，功能是连接的传输层统计信息。

#### 3.1 K-means 聚类

有各种基于分区的聚类算法[7]。 选择K-Means算法是因为它是最快速和最简单的算法之一。 K-Means算法将数据集中的对象划分为固定数量的K个不相交子集。 对于每个群集，分区算法通过最小化平方误差来最大化群集内的同质性。 平方误差的公式为：
$$
E=\sum_{i=1}^{K} \sum_{j=1}^{n}\left|\operatorname{dist}\left(x_{j}, c_{i}\right)\right|^{2}
$$
平方误差计算为每个对象x与其簇的中心（或平均值）之间的距离平方。 对象c表示每个簇的相应中心。

使用以下算法通过K-Means最小化平方误差。 K簇的中心最初是从子空间内随机选择的。 然后，数据集中的对象被分区到最近的集群中。 K-Means迭代地计算所形成的聚类的新中心，然后基于新中心对它们进行重新分配。 K-Means算法继续此过程，直到集群内的成员资格稳定，从而产生最终分区。 该算法在本文测试的数据集的少量迭代中收敛。

#### 3.2 DBSCAN聚类

基于密度的算法将群集视为由较不密集区域分隔的对象的密集区域。 这些聚类算法优于基于分区的算法，因为它们不仅限于寻找球形聚类，而是可以找到任意形状的聚类。 在本文中，DBSCAN（基于密度的噪声应用空间聚类）算法被选为基于密度的算法的代表[5]。

DBSCAN算法基于密度可达性和密度连通性的概念。这些概念取决于两个输入参数：epsilon（eps）和最小点数（minPts）。 Epsilon是定义其eps邻域的对象周围的距离。对于给定对象q，当eps-neighborhood内的对象数量至少为minPts时，则q被定义为核心对象。其eps邻域内的所有对象都被称为从q直接密度可达。另外，如果对象p在可直接密度可达或密度可从q到达的对象的eps邻域内，则称对象p是密度可达的。此外，如果存在p和q都是密度可达的对象o，则称对象p和q是密度连接的。
密度可达性和密度连通性的这些概念用于定义DBSCAN算法认为的聚类。集群被定义为数据集中的对象集，其密度连接到特定核心对象。任何不属于群集的对象都被归类为噪声。这与K-Means和AutoClass形成对比，后者将每个对象分配给一个集群。
DBSCAN算法的工作原理如下。最初，假设数据集中的所有对象都是未分配的。然后，DBSCAN从数据集中选择任意未分配的对象p。如果DB-SCAN发现p是核心对象，它会根据eps和minPts找到所有密度连接的对象。它将所有这些对象分配给新的群集。如果DBSCAN发现p不是核心对象，则p被认为是噪声，DBSCAN移动到下一个未分配的对象。一旦分配了每个对象，算法就会停止。

#### 3.3 AutoClass

先前在[10,17]中考虑的基于概率模型的聚类是另一种强大的聚类技术。我们使用一种基于概率模型的聚类技术实现，称为AutoClass [1]。该算法允许自动选择簇的数量和数据的软聚类。软群集允许将数据对象分数分配给多个群集。对于我们的工作，我们使用最可能的赋值作为对象的赋值。
为了构建概率模型，聚类算法确定聚类的数量和控制每个聚类的不同概率分布的参数。为此，AutoClass使用期望最大化（EM）算法[2]。 EM算法有两个步骤：期望步骤和最大化步骤。初始期望步骤猜测参数使用伪随机数。在最大化步骤中，使用均值和方差来连续地重新估计参数，直到它们收敛到局部最大值。记录这些局部最大值并重复EM过程。这个过程一直持续到找到足够的参数样本（我们在结果中使用200个循环）。 AutoClass使用贝叶斯分数来确定用于概率模型的最佳参数集。贝叶斯分数基于群集内相似性和群集间不相似性。此外，贝叶斯分数会惩罚具有更多聚类的模型，以最大限度地减少潜在的过度拟合。

### METHODOLOGY

#### 4.1 Empirical Traces

为了分析算法，我们使用了来自两个经验包跟踪的数据。一个是公开可用的数据包跟踪，称为Auck-land IV2，另一个是我们在卡尔加里大学收集的完整数据包跟踪。
奥克兰IV：奥克兰四号航迹仅包含通过奥克兰大学与互联网相连的流量的TCP / IP负责人。我们使用了2001年3月16日06:00:00至2001年3月19日05:59:59的奥克兰IV踪迹的子集。该子集提供了足够的连接样本来构建我们的模型（参见第4.4节）。
卡尔加里：这条踪迹是从连接到卡尔加里大学互联网链接的交通监控器收集的。我们在2006年3月10日下午1点到2点收集了这条迹线。此跟踪是一个完整的数据包跟踪，其中包含捕获的所有数据包的全部有效负载。由于捕获完整有效负载时生成的数据量，我们的流量监视器的磁盘容量（60 GB）在收集一小时后被填充，从而限制了跟踪的持续时间。

#### 4.2 Connection Identification

要收集聚类评估所需的统计流信息，必须在跟踪中识别流。这些流（也称为连接）是两个节点之间的数据包双向交换。
在跟踪中，数据不仅仅来自基于连接的传输层协议，例如TCP。虽然本研究仅关注基于TCP的应用程序，但应注意的是，也可以为UDP流量计算统计流量信息。我们使用TCP的3次握手确定了连接的开始，并在收到FIN / RST数据包时终止了连接。此外，如果连接空闲超过90秒，我们假设流程终止。
所考虑的统计流量特性包括：数据包总数，平均数据包大小，不包括报头的平均有效负载大小，传输的字节数（在每个方向和组合）以及数据包的平均到达间隔时间。我们使用这些特征的决定主要基于Zander等人之前的工作。 [17]。由于许多特征的重尾分布以及我们使用欧几里德距离作为我们的相似性度量，我们发现特征的对数为所有聚类算法提供了更好的结果[13,16]。

#### 4.3 Classification of the Data Sets

公开提供的奥克兰IV痕迹不包括有效载荷信息。因此，要确定连接“真实”分类，请使用端口号。对于此跟踪，我们认为基于端口的分类在很大程度上是准确的，因为这种归档跟踪早于广泛使用动态端口号。考虑用于Auckland IV数据集的类是DNS，FTP（控制），FTP（数据），HTTP，IRC，LIMEWIRE，NNTP，POP3和SOCKS。 LimeWire是一个使用Gnutella协议的P2P应用程序。
在卡尔加里追踪中，我们能够捕获数据包的完整有效载荷，因此能够使用基于有效载荷的自动分类来确定“真实”类。我们使用的基于有效载荷的分类算法和签名非常类似于Karagiannis等人描述的算法和签名。 [9]。我们扩充了他们的签名，以对一些较新的P2P应用程序和即时消息程序进行分类。考虑用于卡尔加里跟踪的流量类是HTTP，P2P，SMTP和POP3。卡尔加里迹线的应用细分见表1.由于空间限制，奥克兰IV迹线的细分已被省略。然而，HTTP也是占据76％以上字节和连接的最主要的应用程序。

#### 4.4 Testing Methodology

两条迹线中的大多数连接都带有HTTP流量。这种不平等的分布不允许对不同类别进行相同的测试。为了解决这个问题，用于聚类的奥克兰数据集由每个交通类别的1000个随机样本组成，而卡尔加里数据集使用每个交通类别的2000个随机样本。这允许测试结果公平地判断所有流量的能力而不仅仅是HTTP。数据集的大小限制为8000个连接，因为这是AutoClass算法可以在合理的时间内（4-10小时）聚集的上限。此外，为了对结果更有信心，我们为每条迹线生成了10个不同的数据集。然后，这些数据集中的每一个用于评估聚类算法。我们报告每条迹线的数据集的最小值，最大值和平均值。
在未来，我们计划研究实际问题，即选择用作构建模型的样本的连接的最佳方法是什么。我们认为可以实现的一些方法是通过随机选择或使用不同标准的加权选择，例如传输的字节数或持续时间。此外，为了获得合理的流量代表模型，需要选择相当大但可管理的样本数量。我们发现K-Means和DBSCAN算法能够在4-10小时内聚集更大的数据集（大于100,000）。

### EXPERIMENTAL RESULTS

在本节中，首先评估每个聚类算法的整体有效性。 接下来，分析算法产生的每个簇中的对象数量。

#### 5.1 Algorithm Effectiveness

使用整体精度计算聚类算法的整体有效性。 此总体准确度测量确定了群集算法能够创建仅包含单个流量类别的群集的程度。
构成群集中大多数连接的流量类用于标记群集。 群集中正确分类的连接数称为真实位置（TP）。 任何未正确分类的连接都被视为误报（FP）。 尚未分配给群集的任何连接都标记为噪声。 因此，总体准确度计算如下：$$\text { overall accuracy }=\frac{\sum T P \text { for all clusters }}{\text { total number of connections}}$$

在以下小节中，介绍了K-Means，DBSCAN和AutoClass算法的有效性。

##### 5.1.1 K-Means Clustering

K-Means算法的输入参数为K.如3.1节所述，该输入参数是K-Means使用的不相交分区的数量。在我们的数据集中，我们预计每个流量类至少会有一个集群。另外，由于HTTP等某些类（例如，浏览，批量下载，流式传输）的流量多样化，我们预计会形成更多的集群。因此，基于此，评估K-Means算法，其中K最初为10，并且对于每个后续聚类，K增加10。 K-Means聚类算法的最小，最大和平均结果如图1所示。
最初，当集群数量较少时，K-Means的总体准确度约为奥克兰IV数据集的49％和卡尔加里数据集的67％。随着集群数量的增加，总体准确性稳步提高。对于奥克兰IV和卡尔加里数据集，这一情况持续到K大约为100，总体准确度分别为79％和84％。在这一点上，改进更为渐进，当两个数据集中K为150时，整体精度仅提高1.0％。当K大于150时，当K为500时，整体精度提高到80％的高范围，进一步减少了改进。然而，大的K值增加了过度拟合的可能性。

##### 5.1.2 DBSCAN Clustering

DBSCAN算法的精度结果如图2所示。回想一下，DBSCAN有两个输入参数（minPts，eps）。我们改变了这些参数，并在图2中报告了产生最佳聚类结果的组合的结果。用于minPts的值在3和24之间进行测试。测试的eps距离为0.005至0.040。图3显示了卡尔加里数据集的（minPts，eps）值的不同组合的结果。正如可以预料的那样，当minPts为3时，产生的结果比minPts为24时更好，因为形成了更小的聚类。使用三个minPts找到的附加簇通常是仅包含3到5个连接的小簇。
当使用等于3的minPts同时改变0.005到0.020之间的eps距离时（参见图2），DBSCAN算法将Auckland IV数据集的总体准确度从59.5％提高到75.6％。对于卡尔加里数据集，DBSCAN算法将其整体精度从32.0％提高到72.0％，因为eps距离随着这些相同值而变化。随着距离的增加，eps距离大于0.020的整体精度显着下降。我们的分析表明，这种大幅度的降低是因为不同流量类的集群合并为一个大型集群。我们发现这个较大的集群用于少量数据包，少量字节传输和短持续时间的连接。此群集通常包含等量的P2P，POP3和SMTP连接。许多SMTP连接用于连接到SMTP服务器后，收件人地址被拒绝且连接立即关闭的电子邮件。对于POP3，许多连接包含用户邮箱中没有电子邮件的实例。尝试连接到远程节点并且其“GNUTELLA CONNECT”数据包被拒绝的Gnutella客户端占据了大多数P2P连接。

##### 5.1.3 AutoClass Clustering

表2中显示了AutoClass算法的结果。对于此算法，将自动确定群集数和群集参数。 总的来说，AutoClass算法具有最高的准确性。 平均而言，AutoClass在奥克兰IV和卡尔加里数据集中的准确率分别为92.4％和88.7％。 AutoClass为Auckland IV数据集平均生成167个集群，为Calgary数据集生成247个集群。

#### 5.2 Cluster Weights

对于流量分类问题，聚类算法生成的聚类数量是一个重要的考虑因素。 原因是一旦聚类完成，每个聚类都必须被标记。 在分类阶段，最小化簇的数量也是成本有效的。
减少要标记的集群数量的一种方法是通过评估其中包含许多连接的集群。 例如，如果具有高精度的聚类算法将大多数连接置于聚类的一小部分中，则通过仅分析该子集，可以对大多数连接进行分类。 图4显示了使用Auckland IV数据集表示为群集增加百分比的连接百分比。 在这种评估中，K-Means算法的K值为100.对于DBSCAN和AutoClass算法，无法设置簇的数量。

DBSCAN使用0.03表示eps，3表示minPts，平均有190个簇。 我们选择了这一点，因为它为DBSCAN提供了最佳的整体准确性。 AutoClass平均有167个集群。
如图4所示，K-Means和AutoClass都具有比DBSCAN更均匀分布的集群。 由K-Means生产的15个最大的集群仅包含50％的连接。 相反，对于DBSCAN算法，五个最大的簇包含数据集中超过50％的连接。 这五个集群确定了75.4％的NNTP，POP3，SOCKS，DNS和IRC连接，总体准确率为97.6％。 当考虑通过仅查看190个集群中的五个集群时，可以识别出大部分流量，这些结果是不可预期的。 获得了卡尔加里数据集的定性相似结果。

### DISCUSSION

DBSCAN算法是本文中考虑的唯一算法，可以将连接标记为噪声。 K-Means和AutoClass算法将每个连接都放入一个集群中。被标记为噪声的连接降低了DBSCAN算法的整体精度，因为它们被视为错误分类。通过排除标记为噪声的连接并仅检查由DBSCAN生成的簇，我们发现了一些有趣的结果。图5显示了使用卡尔加里数据集的DBSCAN（eps = 0.02，minPts = 3），K-Means（K = 190）和AutoClass算法的精度值。精度是流量等级的TP与FP的比率。 Precision测量集群的准确性，以对特定类别的流量进行分类。
图5显示，对于卡尔加里数据集，DBSCAN算法具有四种流量中三种流量的最高精度值。虽然没有显示奥克兰IV数据集，但九个流量类别中有七个的平均精度值超过95％。这表明虽然DBSCAN的整体准确度低于K-Means和AutoClass，但它可以产生高度精确的聚类。
聚类算法之间另一个值得注意的差异是构建模型所需的时间。平均来构建模型，K-Means算法需要1分钟，DBSCAN算法需要3分钟，而AutoClass算法需要4.5小时。显然，AutoClass的模型构建阶段是耗时的。我们相信这可能会阻止系统开发人员使用此算法，即使重新训练模型的频率很低。

### CONCLUSIONS

在本文中，我们针对网络流量分类问题评估了三种不同的聚类算法，即K-Means，DBSCAN和AutoClass。我们的分析基于每种算法生成具有单一流量类别的高预测能力的群集的能力，并且每种算法能够生成包含大多数连接的最少数量的群集。结果表明，AutoClass算法产生最佳的整体精度。但是，DBSCAN算法具有很大的潜力，因为它将大多数连接放在集群的一小部分中。这非常有用，因为这些集群具有单一类别流量的高预测能力。 K-Means算法的整体精度仅略低于AutoClass算法，但由于模型构建时间快得多，因此更适合此问题。我们正在进行中，我们将继续研究这些和其他聚类算法，以用作有效的分类工具。 

